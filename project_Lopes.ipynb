{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa6e4a4c",
   "metadata": {},
   "source": [
    "# App Subscription Project\n",
    "\n",
    "by Carolina S. Lopes\n",
    "\n",
    "**STRV DATA SCIENCE ACADEMY**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1879846e",
   "metadata": {},
   "source": [
    "## Defining the business problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3150155",
   "metadata": {},
   "source": [
    "## Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af384ac",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b7c195",
   "metadata": {},
   "source": [
    "We'll start our analysis by loading all necessary Python libraries in order to perform our project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95293452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c9ed05",
   "metadata": {},
   "source": [
    "#### Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d739cc26",
   "metadata": {},
   "source": [
    "The project's main dataset is available on the Kaggle platform. \n",
    "In order to download it, please check this [link](https://www.kaggle.com/datasets/hkhamnakhalid/customers-to-subscription-through-app-behavior).\n",
    "\n",
    "After downloading the dataset, you need to provide the filepath in order to read it with the help of pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7980dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/csergilo/Desktop/strv-ds-academy/app-subscription-strv-academy/datasets/FineTech_appData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5208ea21",
   "metadata": {},
   "source": [
    "Let's check if the loaded dataset is consistent to what is available on Kaggle page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28bff1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>first_open</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "      <th>age</th>\n",
       "      <th>screen_list</th>\n",
       "      <th>numscreens</th>\n",
       "      <th>minigame</th>\n",
       "      <th>used_premium_feature</th>\n",
       "      <th>enrolled</th>\n",
       "      <th>enrolled_date</th>\n",
       "      <th>liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235136</td>\n",
       "      <td>2012-12-27 02:14:51.273</td>\n",
       "      <td>3</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>idscreen,joinscreen,Cycle,product_review,ScanP...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333588</td>\n",
       "      <td>2012-12-02 01:16:00.905</td>\n",
       "      <td>6</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>24</td>\n",
       "      <td>joinscreen,product_review,product_review2,Scan...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>254414</td>\n",
       "      <td>2013-03-19 19:19:09.157</td>\n",
       "      <td>1</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>Splash,Cycle,Loan</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>234192</td>\n",
       "      <td>2013-07-05 16:08:46.354</td>\n",
       "      <td>4</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>product_review,Home,product_review,Loan3,Finan...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-07-05 16:11:49.513</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51549</td>\n",
       "      <td>2013-02-26 18:50:48.661</td>\n",
       "      <td>1</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>31</td>\n",
       "      <td>idscreen,joinscreen,Cycle,Credit3Container,Sca...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-26 18:56:37.841</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user               first_open  dayofweek       hour  age  \\\n",
       "0  235136  2012-12-27 02:14:51.273          3   02:00:00   23   \n",
       "1  333588  2012-12-02 01:16:00.905          6   01:00:00   24   \n",
       "2  254414  2013-03-19 19:19:09.157          1   19:00:00   23   \n",
       "3  234192  2013-07-05 16:08:46.354          4   16:00:00   28   \n",
       "4   51549  2013-02-26 18:50:48.661          1   18:00:00   31   \n",
       "\n",
       "                                         screen_list  numscreens  minigame  \\\n",
       "0  idscreen,joinscreen,Cycle,product_review,ScanP...          15         0   \n",
       "1  joinscreen,product_review,product_review2,Scan...          13         0   \n",
       "2                                  Splash,Cycle,Loan           3         0   \n",
       "3  product_review,Home,product_review,Loan3,Finan...          40         0   \n",
       "4  idscreen,joinscreen,Cycle,Credit3Container,Sca...          32         0   \n",
       "\n",
       "   used_premium_feature  enrolled            enrolled_date  liked  \n",
       "0                     0         0                      NaN      0  \n",
       "1                     0         0                      NaN      0  \n",
       "2                     1         0                      NaN      1  \n",
       "3                     0         1  2013-07-05 16:11:49.513      0  \n",
       "4                     0         1  2013-02-26 18:56:37.841      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af2998c",
   "metadata": {},
   "source": [
    "Great! The dataset was uploaded as expected. We can now proceed with the Data Wrangling workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88535941",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbac15bc",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130e4dc0",
   "metadata": {},
   "source": [
    "The number of rows and columns of the dataframe can be checked with the `pd.DataFrame.shape` method as below, and the output is given in the format (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c946ffd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2292993c",
   "metadata": {},
   "source": [
    "The dataframe columns are listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e1b9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user', 'first_open', 'dayofweek', 'hour', 'age', 'screen_list',\n",
       "       'numscreens', 'minigame', 'used_premium_feature', 'enrolled',\n",
       "       'enrolled_date', 'liked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ba334",
   "metadata": {},
   "source": [
    "One important step during Data Wrangling consists in checking the datatypes for each column, and confirm if they are correct. In case they aren't, we need to cast our data to the correct datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4bf7b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user                     int64\n",
       "first_open              object\n",
       "dayofweek                int64\n",
       "hour                    object\n",
       "age                      int64\n",
       "screen_list             object\n",
       "numscreens               int64\n",
       "minigame                 int64\n",
       "used_premium_feature     int64\n",
       "enrolled                 int64\n",
       "enrolled_date           object\n",
       "liked                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ab481b",
   "metadata": {},
   "source": [
    "Another important step is to check whether we have any missing values on our columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb54a542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user                        0\n",
       "first_open                  0\n",
       "dayofweek                   0\n",
       "hour                        0\n",
       "age                         0\n",
       "screen_list                 0\n",
       "numscreens                  0\n",
       "minigame                    0\n",
       "used_premium_feature        0\n",
       "enrolled                    0\n",
       "enrolled_date           18926\n",
       "liked                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e35bb27",
   "metadata": {},
   "source": [
    "As given above, we have many missing entries in the \"enrolled_date\" column. This makes sense, as no date should appear in this field if the user didn't subscribe to the app Premium features.\n",
    "\n",
    "Missing data can also appear as \"0\". Depending on our fields, this may affect the output of any statistical calculations for that column.\n",
    "\n",
    "In the case of our project, a column that could present zero values that don't make sense corresponds to the \"age\". Or are there any babies dealing with FinTech apps already? 🤔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d83adafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([value == 0 for value in df['age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1848b2",
   "metadata": {},
   "source": [
    "Okay, that seems good! Just to be sure, let's also check if any users haven't actually interacted with the app (that is, if there's any entry where `df['numscreens']` is equal to zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "645dbbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([value == 0 for value in df['numscreens']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e163cd2",
   "metadata": {},
   "source": [
    "As nothing seems suspicious with our dataset, let's check our unique values! With this step, we can infer if our columns correspond to numerical or categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b613d413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user                    49874\n",
       "first_open              49747\n",
       "dayofweek                   7\n",
       "hour                       24\n",
       "age                        78\n",
       "screen_list             38799\n",
       "numscreens                151\n",
       "minigame                    2\n",
       "used_premium_feature        2\n",
       "enrolled                    2\n",
       "enrolled_date           31001\n",
       "liked                       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509ca389",
   "metadata": {},
   "source": [
    "Interesting! It seems that we have some non-unique users in our dataset. We can check for duplicate user entries in our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2993f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated(subset=['user']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deb9d70",
   "metadata": {},
   "source": [
    "Now, we can compare that with the amount of duplicated rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1dfe1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6d55d1",
   "metadata": {},
   "source": [
    "We can first remove the duplicated rows, and then check the duplicated users in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0139cddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ea85c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>first_open</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "      <th>age</th>\n",
       "      <th>screen_list</th>\n",
       "      <th>numscreens</th>\n",
       "      <th>minigame</th>\n",
       "      <th>used_premium_feature</th>\n",
       "      <th>enrolled</th>\n",
       "      <th>enrolled_date</th>\n",
       "      <th>liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20029</th>\n",
       "      <td>2477</td>\n",
       "      <td>2013-04-15 17:45:44.684</td>\n",
       "      <td>0</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>29</td>\n",
       "      <td>Loan2,Loan</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27838</th>\n",
       "      <td>2477</td>\n",
       "      <td>2013-04-15 17:45:44.684</td>\n",
       "      <td>0</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>Loan2,Loan</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49052</th>\n",
       "      <td>5867</td>\n",
       "      <td>2013-02-11 08:46:43.530</td>\n",
       "      <td>0</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>Cycle,Home,Institutions,SelectInstitution,Bank...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49397</th>\n",
       "      <td>5867</td>\n",
       "      <td>2013-02-11 08:46:43.530</td>\n",
       "      <td>0</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>Cycle,Home,Institutions,SelectInstitution,Bank...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49509</th>\n",
       "      <td>8767</td>\n",
       "      <td>2013-05-14 23:24:19.949</td>\n",
       "      <td>1</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>36</td>\n",
       "      <td>Splash,idscreen,Cycle,product_review,product_r...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-05-14 23:25:45.033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43600</th>\n",
       "      <td>8767</td>\n",
       "      <td>2013-05-14 23:24:19.949</td>\n",
       "      <td>1</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>34</td>\n",
       "      <td>Splash,idscreen,Cycle,product_review,product_r...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-05-14 23:25:45.033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user               first_open  dayofweek       hour  age  \\\n",
       "20029  2477  2013-04-15 17:45:44.684          0   17:00:00   29   \n",
       "27838  2477  2013-04-15 17:45:44.684          0   17:00:00   27   \n",
       "49052  5867  2013-02-11 08:46:43.530          0   08:00:00   27   \n",
       "49397  5867  2013-02-11 08:46:43.530          0   08:00:00   26   \n",
       "49509  8767  2013-05-14 23:24:19.949          1   23:00:00   36   \n",
       "43600  8767  2013-05-14 23:24:19.949          1   23:00:00   34   \n",
       "\n",
       "                                             screen_list  numscreens  \\\n",
       "20029                                         Loan2,Loan           3   \n",
       "27838                                         Loan2,Loan           3   \n",
       "49052  Cycle,Home,Institutions,SelectInstitution,Bank...          18   \n",
       "49397  Cycle,Home,Institutions,SelectInstitution,Bank...          18   \n",
       "49509  Splash,idscreen,Cycle,product_review,product_r...          22   \n",
       "43600  Splash,idscreen,Cycle,product_review,product_r...          22   \n",
       "\n",
       "       minigame  used_premium_feature  enrolled            enrolled_date  \\\n",
       "20029         0                     1         0                      NaN   \n",
       "27838         0                     1         0                      NaN   \n",
       "49052         0                     0         0                      NaN   \n",
       "49397         0                     0         0                      NaN   \n",
       "49509         0                     0         1  2013-05-14 23:25:45.033   \n",
       "43600         0                     0         1  2013-05-14 23:25:45.033   \n",
       "\n",
       "       liked  \n",
       "20029      0  \n",
       "27838      0  \n",
       "49052      1  \n",
       "49397      1  \n",
       "49509      0  \n",
       "43600      0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = df['user']\n",
    "\n",
    "df_dupl = df[user.isin(user[user.duplicated()])].sort_values(by = ['user'])\n",
    "df_dupl.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2127c0ea",
   "metadata": {},
   "source": [
    "We can see that some of the duplicated users have inconsistent ages. How many non-problematic entries do we have, that is, how many of these rows have consistent user ages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0238adf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "# users = df_dupl['user'].to_numpy()\n",
    "# print(sum(users[::2] == users[1::2])) # compares both duplicated user entries. all even and odd entries are equal!\n",
    "\n",
    "ages = df_dupl['age'].to_numpy()\n",
    "print(sum(ages[::2] == ages[1::2])) # compares both duplicated user entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c1b90",
   "metadata": {},
   "source": [
    "This means that most of our duplicated entries have are inconsistent in the user ages. We are then deleting all duplicate user entries and updating our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a09a4b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['user'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80bbd47",
   "metadata": {},
   "source": [
    "Resetting the indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf1de6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3532ca",
   "metadata": {},
   "source": [
    "Now we're good to go! Focusing back on our categorical and numerical variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f886acb1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <b> Click here to check the summary of our variables <b> </summary>\n",
    "    \n",
    "\n",
    "**Categorical variables**\n",
    "\n",
    "- **user**: unique values corresponding to user ID\n",
    "\n",
    "- **dayofweek:** values ranging from 0 (\"Monday\") to 6 (\"Sunday\"), corresponding to the day of the week\n",
    "\n",
    "- **hour:** time category from 00:00:00 to 23:00:00 corresponding to the *first_open* variable\n",
    "\n",
    "- **minigame:** \n",
    "    - 0 → user didn't minigame\n",
    "    - 1 → user played minigame\n",
    "\n",
    "- **used_premium_feature:** \n",
    "    - 0 → user haven't used a Premium feature\n",
    "    - 1 → Premium feature was used\n",
    "        \n",
    "- **liked:** \n",
    "    - 0 → user haven't liked/rated the app\n",
    "    - 1 → user likes the app\n",
    "\n",
    "**Numerical Variables**\n",
    "\n",
    "- **age:** user ages\n",
    "\n",
    "- **numscreens:** number of screens visited by the user\n",
    "\n",
    "**Dates**\n",
    "\n",
    "- **first_open:** time at which user created the account \\\n",
    "\n",
    "- **enrolled_date:** day at which user subscribed to Premium\n",
    "\n",
    "    \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c19767",
   "metadata": {},
   "source": [
    "Let's create some new binned categories to enrich our analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e842c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# day periods: (0) night (1) morning (2) afternoon (3) evening\n",
    "\n",
    "df['hour'] = df['hour'].apply(lambda value: int(value.strip()[0:2]))\n",
    "df['dayperiod'] = df['hour'].apply(lambda value: ((0 if value >= 0 and value <= 5 else 1) if value <= 11 else 2) if value <= 17 else 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b35fd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.enrolled_date = pd.to_datetime(df.enrolled_date)\n",
    "df.first_open = pd.to_datetime(df.first_open)\n",
    "\n",
    "df['days_to_enroll'] = round((df.enrolled_date - df.first_open) / pd.Timedelta(days=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55846bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age groups: (0) 18-24 (1) 25-34 (2) 35-44 (3) 45-54 (4) 55-64 (5) 65+\n",
    "\n",
    "df['age_group'] = df['age'].apply(lambda age: ((((0 if age >= 18 and age <= 24 else 1) if age <= 34 else 2) if age <= 44 else 3) if age <= 54 else 4) if age <= 64 else 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0456bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f58cf0",
   "metadata": {},
   "source": [
    "Our dataframe categories are now as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4118dc7",
   "metadata": {},
   "source": [
    "Getting back to our dataframe, there's one column that needs special attention: the \"screen_list\" column. If we scroll up a bit, we can see that this column has more than 38000 unique values. That is because the entries correspond to strings with all screens that a given user has visited.\n",
    "\n",
    "To start analysing this data, we can first turn the entries into lists with the screen names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeeff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['screen_list'] = df['screen_list'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd8607",
   "metadata": {},
   "source": [
    "And then check with how many and which unique screen names we're dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71116ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_items = df['screen_list'].notnull()\n",
    "all_screens = set()\n",
    "\n",
    "for i, item in enumerate (list_items):\n",
    "        \n",
    "    if item == True:\n",
    "\n",
    "            entry = df['screen_list'][i]\n",
    "\n",
    "            for j in entry:\n",
    "\n",
    "                # adicionar diferentes itens da coluna em um set\n",
    "                all_screens.add(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50775eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_screens = len(all_screens)\n",
    "total_screens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91098766",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_screens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6cac0",
   "metadata": {},
   "source": [
    "From the output, we can see that there are many similar screens. For example, we can check the screens starting with \"Credit\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ec2743",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in all_screens if i.startswith(\"Credit\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162656fe",
   "metadata": {},
   "source": [
    "We can group these screen names in order to reduce our data. Let's define a function that will do this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0373e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_screens(group):\n",
    "\n",
    "    for i, item in enumerate(df['screen_list']):\n",
    "\n",
    "        for j, jtem in enumerate((pd.Series(df['screen_list'][i])).str.startswith(group)):\n",
    "\n",
    "            if jtem == True:\n",
    "\n",
    "                df['screen_list'][i][j] = group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fce477",
   "metadata": {},
   "source": [
    "The function `group_screens` is able to replace all entries starting with a given string by this string. For example: if we call the function `group_screens('Credit')`, it will replace all string starting with \"Credit\" by \"Credit\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110e73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_screens('Credit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767baa8b",
   "metadata": {},
   "source": [
    "We can do the same for other categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbf74ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "screens_to_group = ['Loan', 'Profile', 'Saving', 'Verify', 'product_review']\n",
    "\n",
    "for s in screens_to_group:\n",
    "    \n",
    "    group_screens(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6725e27",
   "metadata": {},
   "source": [
    "Our dataset is now as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a3f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a548bb6d",
   "metadata": {},
   "source": [
    "To enrich our analysis, we can add some numerical columns to our dataset corresponding to screen counts of the screen_list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467079ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_screens'] = df['screen_list'].apply(lambda value: len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b70af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_screens(name):\n",
    "    \n",
    "    screen_count = []\n",
    "    \n",
    "    for i, item in enumerate(df['screen_list']):\n",
    "        \n",
    "        name_list = []\n",
    "\n",
    "        for j, jtem in enumerate((pd.Series(df['screen_list'][i]))):\n",
    "\n",
    "            if jtem == name:\n",
    "\n",
    "                name_list.append(name)\n",
    "    \n",
    "        screen_count.append(len(name_list))\n",
    "        \n",
    "    return(screen_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02197088",
   "metadata": {},
   "outputs": [],
   "source": [
    "screens_to_group = ['Credit', 'Loan', 'Profile', 'Saving', 'Verify', 'product_review']\n",
    "screen_count = []\n",
    "\n",
    "for s in screens_to_group:\n",
    "        \n",
    "    screen_count.append(count_screens(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e795dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['credit_screens'] = screen_count[0]\n",
    "df['loan_screens'] = screen_count[1]\n",
    "df['prof_screens'] = screen_count[2]\n",
    "df['sav_screens'] = screen_count[3]\n",
    "df['ver_screens'] = screen_count[4]\n",
    "df['prod_rvw_screens'] = screen_count[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507c9388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc8ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['user', 'first_open', 'screen_list', 'enrolled_date'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d28059",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c411700",
   "metadata": {},
   "source": [
    "Starting with the EDA, let's check some of the dataframe parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ecdba3",
   "metadata": {},
   "source": [
    "Now that our dataset is cleaner and easier to work with, let's check the correlation between our numerical variables and our category \"enrolled\", which is 0 if user didn't subscribe to Premium and 1 if user subscribed to Premium.\n",
    "\n",
    "We can start by checking some of our dataset parameters, and then define a smaller dataset derived from our main dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7590095",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccdd464",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df[['age', 'numscreens','enrolled']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b3ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de334756",
   "metadata": {},
   "source": [
    "The method `pd.DataFrame.corr`is able to calculate the correlation between our variables. Let's plot the outcome in a heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e55a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_num.corr(method=\"pearson\", numeric_only = False), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b5f91b",
   "metadata": {},
   "source": [
    "From the plot, we can see that numscreens and age have low positive and low negative correlation with \"enrolled\", respectively. \n",
    "\n",
    "Let's check the pairplot regarding these variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6bc018",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df_num, hue = 'enrolled', height=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a61e54",
   "metadata": {},
   "source": [
    "Now, let's check the correlation between all categorical variables and label \"enrolled\".\n",
    "\n",
    "The correlation between two categorical variables is calculated in a different manner compared to the correlation between a numerical and a categorical variable.\n",
    "\n",
    "In the next steps, we'll use a function that calculates the Chi-square test of independence between two categorical variables. First, we build a cross table between two attributes using the `pd.DataFrame.crosstab` method. Next, this table is used to perform the Chi-square test.\n",
    "\n",
    "The Chi-Square test returns an array of parameters that are used to understand the correlation between two variables in the following manner:\n",
    "\n",
    "**Chi-square test**\n",
    "    Let's consider we have an Hypothesis H0, that states that two variables are not correlated and an Hypothesis H1, which states that both are correlated. We then calculate the p-value regarding both hypotheses. If `p > 0.05`, H1 is true and H0 is rejected. If `p < 0.05`, H1 is discarded and we consider H0 as true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cfede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findpValues (index, column):\n",
    "    \n",
    "    pValues = []\n",
    "    \n",
    "    for i in index:\n",
    "\n",
    "        crosstab = pd.crosstab(index = df[i], columns = df[column])\n",
    "\n",
    "        chi2 = chi2_contingency(crosstab)\n",
    "        \n",
    "        pValues.append(chi2[1])\n",
    "\n",
    "    return pValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d82dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_Values = findpValues(['dayofweek', 'hour', 'minigame', 'used_premium_feature', 'liked', 'dayperiod'], 'enrolled')\n",
    "p_Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbca09b9",
   "metadata": {},
   "source": [
    "From the output, we now know that \"liked\" is the only attribute which is not correlated to \"enrolled\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc658416",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7953b558",
   "metadata": {},
   "source": [
    "**Balanced / Imbalanced data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0a7522",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "sns.countplot(data=df, x='hour', ax=axes[0])\n",
    "sns.countplot(data=df, x='dayperiod', ax=axes[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c8e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "sns.countplot(data=df, x='age', ax=axes[0])\n",
    "sns.countplot(data=df, x='age_group', ax=axes[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fe9790",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00348e8a",
   "metadata": {},
   "source": [
    "## ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb26709b",
   "metadata": {},
   "source": [
    "### Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb1cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['enrolled', 'days_to_enroll'] , axis=1)\n",
    "y = df['enrolled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8721600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.head()\n",
    "# y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf3aa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ae4450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical columns\n",
    "cat_cols = ['dayofweek', 'hour', 'age', 'minigame', 'used_premium_feature', 'liked', 'dayperiod', 'age_group']\n",
    "\n",
    "# numerical columns\n",
    "num_cols = ['age', 'numscreens']\n",
    "\n",
    "# numerical columns from transformations\n",
    "num_cols_screens = ['days_to_enroll', 'credit_screens', 'loan_screens', 'prof_screens', 'sav_screens', 'ver_screens', 'prod_rvw_screens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2de5119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(cat_cols=[], num_cols=[], classifier = RandomForestClassifier(max_depth=5)):\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        [\n",
    "            ('ohe', OneHotEncoder(sparse=False, drop='first', handle_unknown='ignore'), cat_cols),\n",
    "            ('scale', StandardScaler(), num_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', classifier)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return clf\n",
    "#     return preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e510e6",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click here to understand the contents of our pipeline</summary>\n",
    "## Contents\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ce6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(cat_cols, num_cols)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84fb09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# store results in a dictionary \n",
    "results = clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a82a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabd34ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e5db1b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b628ee7f",
   "metadata": {},
   "source": [
    "# Drafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fa79ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv('/Users/csergilo/Desktop/strv-ds-academy/app-subscription-strv-academy/datasets/clean_FineTech_appData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9257c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3e9502",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df_clean.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6f684",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_screens = pd.read_csv('/Users/csergilo/Desktop/strv-ds-academy/app-subscription-strv-academy/datasets/top_screens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca7fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_screens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e22dd9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819864b0",
   "metadata": {},
   "source": [
    "#### Casting categorical variables\n",
    "\n",
    "Based on the summary above and on the dtypes and unique values we encountered, let's cast some of our variables as categorical data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727edfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dayofweek'] = pd.Categorical(df['dayofweek'], categories=list(range(0, 7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['hour'] = df['hour'].apply(lambda value: int(value.strip()[0:2]))\n",
    "df['hour'] = pd.Categorical(df['hour'], categories=list(range(0, 24)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 00:00 -> 05:00 night; 06:00 -> 11:00 morning; 12:00 -> 17:00 afternoon; 18:00 -> 23:00 evening\n",
    "\n",
    "df['dayperiod'] = df['hour'].apply(lambda value: (('night' if value >= 0 and value <= 5 else 'morning') if value <= 11 else 'afternoon') if value <= 17 else 'evening')\n",
    "df['dayperiod'] = pd.Categorical(df['dayperiod'], categories=['night', 'morning', 'afternoon', 'evening'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['minigame'] = pd.Categorical(df['minigame'], categories=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e6c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['used_premium_feature'] = pd.Categorical(df['used_premium_feature'], categories=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['liked'] = pd.Categorical(df['liked'], categories=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a13e0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['enrolled'] = pd.Categorical(df['enrolled'], categories=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f0c6d8",
   "metadata": {},
   "source": [
    "We can also cast the user ID as a string, so that no erroneous statistical methods are applied to this category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1245c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['user'] = df['user'].apply(str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
